{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License.\n",
    "\n",
    "# Convert coco annotations to json lines\n",
    "In order to generate models for computer vision, you will need to bring in labeled image data as input for model training in the form of an AzureML Labeled Dataset. You can either use a Labeled Dataset that you have exported from a Data Labeling project, or create a new Labeled Dataset with your labeled training data\n",
    "\n",
    "In this notebook, we go over how you can convert a coco annotation file to a json line file, which can be used to create a LabeledDataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Licensing Information - \n",
    "This preview software is made available to you on the condition that you agree to\n",
    "[your agreement][1] governing your use of Azure, and to the Supplemental Terms of Use for Microsoft Azure Previews[2], which supplement your agreement governing your use of Azure.\n",
    "If you do not have an existing agreement governing your use of Azure, you agree that \n",
    "your agreement governing use of Azure is the [Microsoft Online Subscription Agreement][3]\n",
    "(which incorporates the [Online Services Terms][4]).\n",
    "By using the software you agree to these terms. This software may collect data\n",
    "that is transmitted to Microsoft. Please see the [Microsoft Privacy Statement][5]\n",
    "to learn more about how Microsoft processes personal data.\n",
    "\n",
    "[1]: https://azure.microsoft.com/en-us/support/legal/\n",
    "[2]: https://azure.microsoft.com/en-us/support/legal/preview-supplemental-terms/\n",
    "[3]: https://azure.microsoft.com/en-us/support/legal/subscription-agreement/\n",
    "[4]: http://www.microsoftvolumelicensing.com/DocumentSearch.aspx?Mode=3&DocumentTypeId=46\n",
    "[5]: http://go.microsoft.com/fwlink/?LinkId=248681 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download traning images and validation images\n",
    "In this notebook, we use data for [COCO 2017 Object Detection Task](https://cocodataset.org/#detection-2017) as an example. \n",
    "\n",
    "**NOTE**: The datasets are not trivial. It takes quite a long time to download and convert. They just serve as examples. If you already have your raw data ready in an Azure storage, you can skip the downloading step. Just refer to the annotation convertion part to convert your dataset into json lines.\n",
    "\n",
    "- 2017 Train images [**118K/18GB**]\n",
    "\n",
    "- 2017 Val images [**5K/1GB**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "from zipfile import ZipFile\n",
    "\n",
    "extract_to_dir = 'coco_2017'\n",
    "\n",
    "def downloadAndExtract(url, extract_to_dir):\n",
    "    # download data\n",
    "    data_file = url[url.rfind(\"/\")+1:]\n",
    "    print(f'Downloading file {data_file}.')\n",
    "    urllib.request.urlretrieve(url, filename=data_file)\n",
    "    print(f'Downloaded {data_file}.')\n",
    "\n",
    "    # extract files\n",
    "    with ZipFile(data_file, 'r') as zip:\n",
    "        print(f'Extracting file {data_file}.')\n",
    "        zip.extractall(path=extract_to_dir)\n",
    "        print(f'Extracted file {data_file}.')\n",
    "\n",
    "    # delete zip file\n",
    "    os.remove(data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017 Train images [118K/18GB]\n",
    "train_url = \"http://images.cocodataset.org/zips/train2017.zip\"\n",
    "# 2017 Val images [5K/1GB] \n",
    "val_url = \"http://images.cocodataset.org/zips/val2017.zip\"\n",
    "    \n",
    "# Download training data and validation data to data folder.\n",
    "downloadAndExtract(train_url, extract_to_dir)\n",
    "downloadAndExtract(val_url, extract_to_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download coco annotations\n",
    "\n",
    "- 2017 Train/Val annotations [**241MB**]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2017 Train/Val annotations [241MB]\n",
    "annoations_url = \"http://images.cocodataset.org/annotations/annotations_trainval2017.zip\"\n",
    "# Download annotation data to data folder.\n",
    "downloadAndExtract(annoations_url, extract_to_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download coco2jsonl converter\n",
    "\n",
    "We created the coco2jsonl converter to help you convert coco annotation files to json line files. It is in [the github repo automlForImages](https://github.com/swatig007/automlForImages). If you already cloned it, you can find it in your local clone folder, then you don't need to download it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download coco2jsonl converter.\n",
    "coco2jsonl_url = 'https://github.com/swatig007/automlForImages/tree/main/MultiClass/utils/coco2jsonl.py'\n",
    "urllib.request.urlretrieve(coco2jsonl_url, filename=\"coco2jsonl.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert coco annotation files to json line files.\n",
    "**NOTE**: The example datasets are not trivial. It takes quite a long time convert. They just serve as examples. Instead of running the example for testing, you may just want to work with your own data by referring to the scripts in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate jsonl file for training data.\n",
    "!python coco2jsonl.py \\\n",
    "--input_coco_file_path \"./coco/annotations/instances_train2017.json\" \\\n",
    "--output_dir \"./coco\" --output_file_name \"instances_train2017.jsonl\" \\\n",
    "--task_type \"ObjectDetection\" \\\n",
    "--base_url \"AmlDatastore://workspaceblobstore/coco_2017/train2017\"\n",
    "\n",
    "# Generate jsonl file for validation data.\n",
    "!python coco2jsonl.py \\\n",
    "--input_coco_file_path \"./coco/annotations/instances_val2017.json\" \\\n",
    "--output_dir \"./coco\" --output_file_name \"instances_val2017.jsonl\" \\\n",
    "--task_type \"ObjectDetection\" \\\n",
    "--base_url \"AmlDatastore://workspaceblobstore/coco_2017/val2017/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (npy37)",
   "language": "python",
   "name": "npy37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
